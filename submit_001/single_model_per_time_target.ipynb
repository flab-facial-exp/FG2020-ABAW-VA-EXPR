{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "create and evaluate single time-window model and single target\n",
    " * select type: \"EXP\", \"VA_V\", \"VA_A\"\n",
    " * select time-window: \"_01s\", \"_06s\", \"_12s\"\n",
    " * create \"au\", \"pose\", \"gaze\", \"openpose\" and \"ensemble\" model\n",
    " * evaluate validation *note* labels are averaged in time-window\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import sklearn #機械学習のライブラリ\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score,mean_squared_error,f1_score\n",
    "from statistics import mean, median,variance,stdev\n",
    "import math\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create base dataset: concat au csv & add label, file count & drop unnecessary columns\n",
    "#   str_substract_time: ex. '02s' , str_search_key: ex. '(Subject_).*.csv'\n",
    "#   cut_start: trim data (X sec from start), cut_end: trim data (X sec from end)\n",
    "def crate_base_data(data_file_names, str_type, str_time):\n",
    "    # create empty dataframe (base dataframe)\n",
    "    #data = pd.DataFrame()\n",
    "    count = 0\n",
    "    max_count = len(data_file_names)\n",
    "    \n",
    "    data_list = [pd.DataFrame()] # <- dummy\n",
    "    \n",
    "    for  data_file in data_file_names:\n",
    "        # read au csv\n",
    "        if os.path.isfile(data_file) and os.path.getsize(data_file) > 32:\n",
    "            data_tmp = pd.read_hdf(data_file)\n",
    "        else:\n",
    "            count = count+1\n",
    "            continue\n",
    "        \n",
    "        if (len(data_tmp)<1):\n",
    "            count = count+1\n",
    "            continue\n",
    "        \n",
    "        # create column - 'count', 'Label', 'subject' (default: 0)\n",
    "        data_tmp[\"count\"] = 0\n",
    "        data_tmp[\"subject\"] = \"sample\"\n",
    "\n",
    "        # convert filename to 'subject'\n",
    "        name_train = os.path.splitext(os.path.basename(data_file))[0].replace(str_time,'')\n",
    "        #print(name_train)\n",
    "\n",
    "        #print(data_temp)\n",
    "        # get and set Label value\n",
    "        data_tmp[\"count\"]  = count\n",
    "        data_tmp[\"subject\"] = name_train\n",
    "        \n",
    "        # drop unnecessary columns\n",
    "        # ' frame-avg',' face_id-avg,' timestamp-avg',' confidence-avg,' success-avg','frame-std',' face_id-std',' confidence-std',' success-std'\n",
    "        data_tmp = data_tmp.drop(['frame-avg',' face_id-avg',' timestamp-avg',' confidence-avg',' success-avg',\n",
    "                                  'frame-std',' face_id-std',' timestamp-std',' confidence-std',' success-std',\n",
    "                                  'frame-range', ' face_id-range', ' timestamp-range', ' confidence-range', ' success-range',\n",
    "                                  'frame-slope', ' face_id-slope', ' timestamp-slope', ' confidence-slope', ' success-slope',\n",
    "                                  'Unnamed: 0-avg', 'Unnamed: 0-std', 'Unnamed: 0-range', 'Unnamed: 0-slope'\n",
    "                               ], axis=1)\n",
    "        if str_type == \"EXP\":\n",
    "            data_tmp = data_tmp.drop(['Neutral-std','Neutral-range','Neutral-slope'], axis=1)\n",
    "        else:\n",
    "            data_tmp = data_tmp.drop(['arousal-std', 'arousal-range', 'arousal-slope', \n",
    "                                     'valence-std', 'valence-range', 'valence-slope'], axis=1)\n",
    "\n",
    "        # append created data to base dataframe\n",
    "        #data = data.append(data_tmp)\n",
    "        data_list.append(data_tmp)\n",
    "\n",
    "        log = 'count: {0}, name: {1}, data shape: {2}'.format(count, name_train, data_tmp.shape)\n",
    "        print(log)\n",
    "        count = count + 1\n",
    "    # finish\n",
    "    del data_list[0]\n",
    "    data = pd.concat([x for x in data_list])\n",
    "    \n",
    "    log = '**** finished creating base dataset, data shape: {0}'.format(data.shape)\n",
    "    print(log)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_balance(data, str_type):\n",
    "    \"\"\"\n",
    "    EXP:  0,  1,  2,  3,  4,  5,  6\n",
    "        0.5,  4, 11,  8,  1,  1,  3\n",
    "    VA:\n",
    "    A|V->        -1                                +1\n",
    "    +1.00~+0.75:  1,  1,   3,  15,  10,   3,   1,   1\n",
    "    +0.75~+0.50:  1,  1,   1,   2,   1,   1,   1,   1\n",
    "    +0.50~+0.25:  5,  1,   1,   2,   1,   1,   1,   5\n",
    "    +0.25~+0.00: 10,  5,   1,   1, 0.5,   1,   5,  20\n",
    "    +0.00~-0.25:  1, 30,  10,   2,   1,  10,   1,   1\n",
    "    -0.25~-0.50:  1, 20,  40,   2,   1,  20,   1,   1\n",
    "    -0.50~-0.75:  1,  1,   1,   2,   2,   1,   1,   1\n",
    "    -0.75~-1.00:  1,  1,   1,   1,   1,   1,   1,   1\n",
    "    \"\"\"\n",
    "    \n",
    "    if str_type == \"EXP\":\n",
    "        data_list = [pd.DataFrame()]*7 # <- dummy\n",
    "        arr = [0.5,  4, 11,  8,  1,  1,  3]\n",
    "        for i in range(7):\n",
    "            data_list[i] = data.loc[data[\"Neutral-avg\"]==i]\n",
    "            if arr[i] < 1:\n",
    "                data_list[i] = data_list[i][::2]\n",
    "            elif arr[i]>=2:                \n",
    "                data_list[i] = data_list[i].append([data_list[i]]*arr[i],ignore_index=True)\n",
    "                \n",
    "        #del data_list[0]\n",
    "        out_data = pd.concat([x for x in data_list])\n",
    "    \n",
    "    else:\n",
    "        data_list = [pd.DataFrame()]*64 # <- dummy\n",
    "        arr = [1,  1,   3,  15,  10,   3,   1,   1,\n",
    "               1,  1,   1,   2,   1,   1,   1,   1,\n",
    "               5,  1,   1,   2,   1,   1,   1,   5,\n",
    "               10,  5,   1,   1, 0.5,   1,   5,  20,\n",
    "               1, 30,  10,   2,   1,  10,   1,   1,\n",
    "               1, 20,  40,   2,   1,  20,   1,   1,\n",
    "               1,  1,   1,   2,   2,   1,   1,   1,\n",
    "               1,  1,   1,   1,   1,   1,   1,   1]\n",
    "        for aro in range(8):\n",
    "            for val in range(8):\n",
    "                i = aro*8 + val\n",
    "                start_a = 1-(aro*0.25)-0.25\n",
    "                stop_a = 1-(aro*0.25)\n",
    "                start_v = val*0.25-1\n",
    "                stop_v = val*0.25-0.75\n",
    "                data_list[i] = data.loc[(data[\"valence-avg\"]>=start_v)&(data[\"valence-avg\"]<=stop_v)&\n",
    "                                        (data[\"arousal-avg\"]>=start_a)&(data[\"arousal-avg\"]<=stop_a)]\n",
    "                if arr[i] < 1:\n",
    "                    data_list[i] = data_list[i][::2]\n",
    "                elif arr[i]>=2:\n",
    "                    data_list[i] = data_list[i].append([data_list[i]]*arr[i],ignore_index=True)\n",
    "                    \n",
    "        out_data = pd.concat([x for x in data_list])\n",
    "        \n",
    "    return out_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split base data to <au>, <gaze and pose>, <eye_landmark, 2d landmark, 3d landmark>\n",
    "# ** 'count','label','subject' is contained in all splits\n",
    "def split_data(in_data):\n",
    "    # au data\n",
    "    df_au = in_data.loc[:, in_data.columns.str.contains(\"AU|count|subject|Neutral|valence|arousal\") ]\n",
    "    #df_au = df_au.join(df_lable)\n",
    "    print(\"AU data shape: \",df_au.shape)\n",
    "\n",
    "    # gaze and pose data **** temp pose\n",
    "    df_pose = in_data.loc[:, in_data.columns.str.contains(\"pose_|count|subject|Neutral|valence|arousal\") ]\n",
    "    #df_pose = df_pose.join(df_lable)\n",
    "    print(\"Gaze & Pose data shape: \",df_pose.shape)\n",
    "    \n",
    "    # eye_landmark, 2d landmark, 3d landmark data **** temp gaze\n",
    "    df_lmk = in_data.loc[:, in_data.columns.str.contains(\"gaze|count|subject|Neutral|valence|arousal\")]\n",
    "    #df_lmk = df_lmk.join(df_lable)\n",
    "    print(\"Landmark data shape: \",df_lmk.shape)\n",
    "    \n",
    "    # openpose\n",
    "    #df_op = in_data.loc[:, ~in_data.columns.str.contains(\"AU|pose_|gaze\")]\n",
    "    df_op = in_data.loc[:, in_data.columns.str.contains(\"hand_flag|0x|0y|0c|1x|1y|1c|2x|2y|2c|3x|3y|3c|4x|4y|4c|5x|5y|5c|6x|6y|6c|7x|7y|7c|8x|8y|8c|9x|9y|9c|10x|10y|10c|11x|11y|11c|12x|12y|12c|13x|13y|13c|14x|14y|14c|15x|15y|15c|16x|16y|16c|17x|17y|17c|18x|18y|18c|19x|19y|19c|20x|20y|20c|21x|21y|21c|22x|22y|22c|23x|23y|23c|24x|24y|24c|count|subject|Neutral|valence|arousal\")]\n",
    "    print(\"Opepose data shape: \",df_op.shape)\n",
    "    \n",
    "    # resnet\n",
    "    df_rn = in_data.loc[:, ~in_data.columns.str.contains(\"AU|pose_|gaze|hand_flag|0x|0y|0c|1x|1y|1c|2x|2y|2c|3x|3y|3c|4x|4y|4c|5x|5y|5c|6x|6y|6c|7x|7y|7c|8x|8y|8c|9x|9y|9c|10x|10y|10c|11x|11y|11c|12x|12y|12c|13x|13y|13c|14x|14y|14c|15x|15y|15c|16x|16y|16c|17x|17y|17c|18x|18y|18c|19x|19y|19c|20x|20y|20c|21x|21y|21c|22x|22y|22c|23x|23y|23c|24x|24y|24c\")]\n",
    "    print(\"Resnet data shape: \",df_rn.shape)\n",
    "    \n",
    "    print(\"** end **\")\n",
    "    return df_au,df_pose,df_lmk,df_op, df_rn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset for single time analysis (Light GBM ...)\n",
    "def make_dataset_for_gbm(in_data, str_type):\n",
    "    \n",
    "    if str_type == \"EXP\":\n",
    "        in_data = in_data[in_data[\"Neutral-avg\"]>=0]\n",
    "        # EXP\n",
    "        # spplit features , labels\n",
    "        data_y = in_data.loc[:,[\"count\", \"subject\", \"Neutral-avg\"]]\n",
    "        data_x = in_data.drop([\"count\", \"subject\", \"Neutral-avg\"], axis=1)\n",
    "    else:\n",
    "        # VA\n",
    "        # spplit features , labels\n",
    "        data_y = in_data.loc[:,[\"count\", \"subject\", \"valence-avg\", \"arousal-avg\"]]\n",
    "        data_x = in_data.drop([\"count\", \"subject\", \"valence-avg\", \"arousal-avg\"], axis=1)\n",
    "    \n",
    "    dim = len(data_x.columns)\n",
    "    \n",
    "    # drop 'count','group' from data_y\n",
    "    data_y = data_y.drop([\"count\", \"subject\"], axis=1) \n",
    "    if str_type == \"VA_A\":\n",
    "        data_y = data_y.drop([\"valence-avg\"], axis=1) \n",
    "    elif str_type == \"VA_V\":\n",
    "        data_y = data_y.drop([\"arousal-avg\"], axis=1) \n",
    "    \n",
    "    # convert pandas to numpy \n",
    "    np_data_x = data_x.values\n",
    "    np_data_y = data_y.values\n",
    "    \n",
    "    # reshape data for tda\n",
    "    np_data_x = np.reshape(np_data_x, [len(np_data_y),dim])\n",
    "    np_data_y = np.reshape(np_data_y, [len(np_data_y),1])\n",
    "\n",
    "    print('** np_data_x',np_data_x.shape)\n",
    "    print('** np_data_y',np_data_y.shape)\n",
    "\n",
    "    return np_data_x, np_data_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_CCC_for_lgbm(preds: np.ndarray, data: lgb.Dataset):\n",
    "    \"\"\"Calculate CCC\"\"\"\n",
    "    # true data\n",
    "    y_true = data.get_label()\n",
    "    # predict data\n",
    "    y_pred = preds.ravel()\n",
    "    \n",
    "    # Calc CCC\n",
    "    x_mean = y_pred.mean()\n",
    "    y_mean = y_true.mean()\n",
    "    sx2 = ((y_pred-x_mean)*(y_pred-x_mean)).mean()\n",
    "    sy2 = ((y_true-y_mean)*(y_true-y_mean)).mean()\n",
    "    sxy = ((y_pred-x_mean)*(y_true-y_mean)).mean()\n",
    "    CCC = (2 * sxy) / (sx2 + sy2 + (x_mean - y_mean) * (x_mean - y_mean))\n",
    "    #score_acc = (2 * sxy) / (sx2 + sy2 + (x_mean - y_mean) * (x_mean - y_mean))\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    score_CCC = 2*CCC-mse\n",
    "    \n",
    "    # name, result, is_higher_better\n",
    "    return 'score_CCC', score_CCC, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_EXP_for_lgbm(preds: np.ndarray, data: lgb.Dataset):\n",
    "    \"\"\"Calculate score EXP (0.67*F1 + 0.33*acc)\"\"\"\n",
    "    # true data\n",
    "    y_true = data.get_label()\n",
    "    # reshape pred\n",
    "    N_LABELS = 7  # number of labels\n",
    "    reshaped_preds = preds.reshape(N_LABELS, len(preds) // N_LABELS)\n",
    "    # 最尤と判断したクラスを選ぶ　\n",
    "    y_pred = np.argmax(reshaped_preds, axis=0)\n",
    "    # calc\n",
    "    score_1 = f1_score(y_true, y_pred, average='macro') # weighted, macro, micro\n",
    "    score_2 = accuracy_score(y_true, y_pred)\n",
    "    score_exp = 0.67*score_1 + 0.33*score_2\n",
    "    # name, result, is_higher_better\n",
    "    return 'score_exp', score_exp, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model and training\n",
    "def create_and_fit_model_GBM(train_x, train_y, validation_x, validation_y, \n",
    "                             learning_rate, num_leaves, num_iter, max_depth, bagging_fraction,\n",
    "                             feature_fraction,min_child_samples,str_type):\n",
    "    # set training, validation data\n",
    "    train_data = lgb.Dataset(train_x, label=train_y)\n",
    "    eval_data = lgb.Dataset(validation_x, label=validation_y, reference= train_data)\n",
    "    \n",
    "    # if target is expression, set parameters to learn [0~6] classification\n",
    "    if str_type == \"EXP\":\n",
    "        params = {\n",
    "            'task': 'train',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'multiclass', #'multiclass','regression','binary'\n",
    "            #'metric':'multi_error', #binary_logloss, binary_error, multi_logloss, multi_error\n",
    "            \"metric\" : \"None\",\n",
    "            'num_leaves':num_leaves,\n",
    "            'learning_rate':learning_rate,\n",
    "            'max_depth':max_depth,\n",
    "            #'num_iterations':num_iter,\n",
    "            'verbosity': -1,\n",
    "            'num_class':7,\n",
    "            'bagging_fraction':bagging_fraction,\n",
    "            'feature_fraction':feature_fraction,\n",
    "            'min_child_samples':min_child_samples\n",
    "        }\n",
    "        # training and return model and data\n",
    "        lgb_model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            valid_sets=eval_data,\n",
    "            num_boost_round=400,\n",
    "            verbose_eval=0,\n",
    "            early_stopping_rounds=20,\n",
    "            feval=score_EXP_for_lgbm  # <= set custom metric function\n",
    "        )\n",
    "    # if target is VA, set parameters to learn -1 ~ 1 regression\n",
    "    else:\n",
    "        params = {\n",
    "            'task': 'train',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression', #'multiclass','regression','binary'\n",
    "            #'metric':'mse', #binary_logloss, binary_error\n",
    "            \"metric\" : \"None\",\n",
    "            'num_leaves':num_leaves,\n",
    "            'learning_rate':learning_rate,\n",
    "            'max_depth':max_depth,\n",
    "            #'num_iterations':num_iter,\n",
    "            'verbosity': -1,\n",
    "            'bagging_fraction':bagging_fraction,\n",
    "            'feature_fraction':feature_fraction,\n",
    "            'min_child_samples':min_child_samples\n",
    "        }\n",
    "        # training and return model and data\n",
    "        lgb_model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            valid_sets=eval_data,\n",
    "            num_boost_round=400,\n",
    "            verbose_eval=0,\n",
    "            early_stopping_rounds=20,\n",
    "            feval=score_CCC_for_lgbm  # <= set custom metric function\n",
    "        )\n",
    "\n",
    "    return lgb_model, train_data, eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predict data\n",
    "def eval_pred(data_true, data_pred, str_type):\n",
    "    score_f1 = 0\n",
    "    score_acc = 0\n",
    "\n",
    "    # if target is expression, calc F1 score, accuracy\n",
    "    if str_type == \"EXP\":\n",
    "        # convert to 7-columns predict probability to 1-column predict\n",
    "        pred_tmp = np.argmax(data_pred, axis=1) # 一番大きい予測確率のクラスを予測クラスに\n",
    "        \n",
    "        ltrue = list(data_true)\n",
    "        lpred = list(pred_tmp) \n",
    "        \n",
    "        score_1 = f1_score(ltrue, lpred, average='macro') # weighted, macro, micro\n",
    "        score_2 = accuracy_score(ltrue, lpred)\n",
    "    # if target is VA, calc CCC, mse\n",
    "    else:\n",
    "        pred_tmp = data_pred\n",
    "        #pred_tmp = data_pred.round()\n",
    "        x_mean = pred_tmp.mean()\n",
    "        y_mean = data_true.mean()\n",
    "        sx2 = ((pred_tmp-x_mean)*(pred_tmp-x_mean)).mean()\n",
    "        sy2 = ((data_true-y_mean)*(data_true-y_mean)).mean()\n",
    "        sxy = ((pred_tmp-x_mean)*(data_true-y_mean)).mean()\n",
    "        score_1 = (2 * sxy) / (sx2 + sy2 + (x_mean - y_mean) * (x_mean - y_mean))\n",
    "        #score_acc = (2 * sxy) / (sx2 + sy2 + (x_mean - y_mean) * (x_mean - y_mean))\n",
    "        score_2 = mean_squared_error(data_true, data_pred)\n",
    "    return score_1, score_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search parameter\n",
    "def search_paramter(train_x, train_y, val_x, val_y, rate_list, leaf_list, n_iter_list, depth_list, child_list, str_type):\n",
    "    model = 0\n",
    "    count = 1\n",
    "    b_frac = 1\n",
    "    f_frac = 1\n",
    "    max_count = len(rate_list)*len(leaf_list)*len(n_iter_list)*len(depth_list)*len(child_list)\n",
    "    \n",
    "    best_score = -1.000\n",
    "    best_socre_1 = -1.000\n",
    "    best_socre_2 = -1.000\n",
    "    best_rate = 0.1\n",
    "    best_leaf = 16\n",
    "    best_iter = 100\n",
    "    best_depth = 8\n",
    "    best_child = 20\n",
    "    \n",
    "    for rate in rate_list:\n",
    "        for leaf in leaf_list:\n",
    "            for n_iter in n_iter_list:\n",
    "                for depth in depth_list:\n",
    "                    for child in child_list:\n",
    "                        \n",
    "                        model, train, validation = create_and_fit_model_GBM(train_x,train_y,val_x,val_y,\n",
    "                                                                        rate,leaf,n_iter,depth,\n",
    "                                                                        b_frac,f_frac,child,\n",
    "                                                                        str_type)\n",
    "                        \n",
    "                        if str_type == \"EXP\":\n",
    "                            pred = model.predict(val_x)\n",
    "                            score_1, score_2 = eval_pred(val_y, pred, str_type)\n",
    "                            score = score_1 * 0.67 + score_2 * 0.33\n",
    "                        else:\n",
    "                            pred = model.predict(val_x).ravel()\n",
    "                            score_1, score_2 = eval_pred(val_y, pred, str_type)\n",
    "                            score = score_1\n",
    "                        \n",
    "                        log = \"{0:00004d}/{1:00004d}  Score: {2:.4f}, score_1: {3:.4f},\"\\\n",
    "                        \" score_2: {4:.4f},rate: {5:.3f}, leaf: {6}, iter: {7}, depth: {8},\"\\\n",
    "                        \" child: {9}\".format(count, max_count, score, score_1, score_2,\n",
    "                                             rate, leaf, n_iter, depth, child)\n",
    "                        print(log)\n",
    "                        if score > best_score:\n",
    "                            best_score = score\n",
    "                            best_socre_1 = score_1\n",
    "                            best_socre_2 = score_2\n",
    "                            best_rate = rate\n",
    "                            best_leaf = leaf\n",
    "                            best_iter = n_iter\n",
    "                            best_depth = depth\n",
    "                            best_child = child\n",
    "\n",
    "                        count = count + 1\n",
    "\n",
    "    log = \"Score: {0:.4f}, score_1: {1:.4f}, score_2: {2:.4f}, rate: {3:.3f}, leaf: {4},\"\\\n",
    "    \" iter: {5}, depth: {6}, child: {7}\".format(best_score, best_socre_1, best_socre_2,\n",
    "                                                best_rate, best_leaf, best_iter, \n",
    "                                                best_depth, best_child\n",
    "                                               )\n",
    "\n",
    "    print(log)\n",
    "    \n",
    "    return best_score, best_socre_1, best_socre_2, best_rate, best_leaf, best_iter, best_depth, best_child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sub_model(train_x, train_y, val_x, val_y, str_type):\n",
    "    # search parameter\n",
    "\n",
    "    # initialize\n",
    "    model = 0\n",
    "    count = 1\n",
    "    b_frac = 1\n",
    "    f_frac = 1\n",
    "    \n",
    "    # first loop\n",
    "    rate_list = [0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0]\n",
    "    leaf_list = [8, 12, 16, 24, 32, 40]\n",
    "    n_iter_list = [100]\n",
    "    depth_list = [ 4, 8, 12, 16]\n",
    "    child_list = [5, 15, 30]\n",
    "\n",
    "    # search param\n",
    "    score, score_1, socre_2, rate, leaf, n_iter, depth, child = search_paramter(train_x, train_y, \n",
    "                                                            val_x, val_y, rate_list, leaf_list, \n",
    "                                                            n_iter_list, depth_list, child_list, str_type)\n",
    "\n",
    "    # next loop\n",
    "    rate_list = [rate-0.1, rate, rate+0.1]\n",
    "    leaf_list = [leaf-2, leaf, leaf+2]\n",
    "    n_iter_list = [n_iter]\n",
    "    depth_list = [ depth-2, depth, depth+2]\n",
    "    child_list = [5, 15, 30]\n",
    "\n",
    "    # search param\n",
    "    score, score_1, socre_2, rate, leaf, n_iter, depth, child = search_paramter(train_x, train_y, \n",
    "                                                            val_x, val_y, rate_list, leaf_list, \n",
    "                                                            n_iter_list, depth_list, child_list, str_type)\n",
    "\n",
    "    log = \"Score: {0:.4f}, score_1: {1:.4f}, score_2: {2:.4f}, rate: {3:.3f}, leaf: {4},\"\\\n",
    "    \" iter: {5}, depth: {6}, child: {7}\".format(score, score_1, socre_2, rate, leaf, \n",
    "                                                n_iter, depth, child )\n",
    "\n",
    "    best_rate = rate\n",
    "    best_leaf = leaf\n",
    "    best_iter = n_iter\n",
    "    best_depth = depth\n",
    "    best_child = child\n",
    "\n",
    "    print(log)\n",
    "\n",
    "    # result:\n",
    "\n",
    "    model, train, validation = create_and_fit_model_GBM(train_x,train_y, val_x, val_y,\n",
    "                                                        best_rate, best_leaf, best_iter, best_depth,\n",
    "                                                        b_frac, f_frac, best_child,\n",
    "                                                        str_type)\n",
    "\n",
    "    # calc score and print parameter\n",
    "    if str_type == \"EXP\":\n",
    "        pred = model.predict(val_x) # 7-columns\n",
    "        score_1, score_2 = eval_pred(val_y, pred, str_type)\n",
    "        score = score_1 * 0.67 + score_2 * 0.33\n",
    "    else:\n",
    "        pred = model.predict(val_x).ravel() # 1-columns to list\n",
    "        score_1, score_2 = eval_pred(val_y, pred, str_type)\n",
    "        score = score_1\n",
    "\n",
    "    log_res = \"Score: {0:.4f}, score_1: {1:.4f}, score_2: {2:.4f}, rate: {3:.3f}, leaf: {4}, iter: {5},\"\\\n",
    "    \" depth: {6}, child: {7}\".format(score, score_1, score_2, rate, leaf,n_iter, depth, child)\n",
    "    print(log)\n",
    "\n",
    "    # self predict\n",
    "    #proba_lmk_train = model.predict_proba(train_x)\n",
    "    pred_train = model.predict(train_x)\n",
    "\n",
    "    # val predict\n",
    "    #proba_lmk_val = model.predict_proba(val_x)\n",
    "    pred_val = model.predict(val_x)\n",
    "    \n",
    "    return model, pred_train, pred_val, log_res\n",
    "    \n",
    "    \"\"\"\n",
    "    # save model\n",
    "    f = dir_out + 'model_rn' + str_footer + str_time + '.pickle'\n",
    "    with open(f, mode='wb') as fp:\n",
    "        pickle.dump(model, fp)\n",
    "    #\n",
    "\n",
    "    # self predict\n",
    "    #proba_lmk_train = model.predict_proba(train_x)\n",
    "    pred_rn_train = model.predict(train_x)\n",
    "\n",
    "    # val predict\n",
    "    #proba_lmk_val = model.predict_proba(val_x)\n",
    "    pred_rn_val = model.predict(val_x)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substruct_features(data, fp, str_type, window_time):\n",
    "    col = str(window_time).zfill(2) + \"s\"\n",
    "    data_f = pd.read_csv(fp)\n",
    "    \n",
    "    if str_type == \"EXP\":\n",
    "        list_f = list(data_f[col].values.ravel())\n",
    "        list_f = np.append(list_f, [\"count\", \"subject\", \"Neutral-avg\"])\n",
    "    else:\n",
    "        list_f = list(data_f[col].values.ravel())\n",
    "        list_f = np.append(list_f, [\"count\", \"subject\", \"valence-avg\", \"arousal-avg\"])\n",
    "    \n",
    "    data2 = data[list_f]\n",
    "    \n",
    "    return data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_single_model(dir_train, dir_val, dir_out, target, window_time, balance = True, dir_features = None):\n",
    "    str_type = target\n",
    "    str_time = \"_{0}s\".format(str(window_time).zfill(2))\n",
    "    str_footer = \"_gbm_\" + str_type\n",
    "    log = \"Target type: {0}, time: {1}s\".format(str_type, window_time)\n",
    "    print(log)\n",
    "    \n",
    "    # search files of training data\n",
    "    file_train = dir_train + \"*\" + str_time + \".h5\"\n",
    "    files_train = [\n",
    "        filename for filename in sorted(glob.glob(file_train))\n",
    "    ]\n",
    "    log = \"file number of training: {0}\".format(len(files_train))\n",
    "    print(log)\n",
    "    \n",
    "    # search files of validation data\n",
    "    file_val = dir_val + \"*\" + str_time + \".h5\"\n",
    "    files_val = [\n",
    "        filename for filename in sorted(glob.glob(file_val))\n",
    "    ]\n",
    "    log = \"file number of validation: {0}\".format(len(files_val))\n",
    "    print(log)\n",
    "\n",
    "    # create base dataset\n",
    "    log = \"data loading....\"\n",
    "    print(log)\n",
    "    #data_train = pd.read_hdf(file_train, 'key')\n",
    "    data_train = crate_base_data(files_train, str_type, str_time)\n",
    "    log = \"data training shape: {0}\".format(data_train.shape)\n",
    "    print(log)\n",
    "    #data_val = pd.read_hdf(file_val, 'key')\n",
    "    data_val = crate_base_data(files_val, str_type, str_time)\n",
    "    log = \"data validation shape: {0}\".format(data_val.shape)\n",
    "    print(log)\n",
    "    \n",
    "    # \"change EXP:-1 to 0\"\n",
    "    if str_type == \"EXP\":\n",
    "        # cut EXP:-1\n",
    "        data_train2 = data_train[data_train['Neutral-avg'] >= 0]\n",
    "        data_val2 = data_val[data_val['Neutral-avg'] >= 0]\n",
    "    else:\n",
    "        data_train2 = data_train\n",
    "        data_val2 = data_val\n",
    "    # \"cut nan\"\n",
    "    log = \" src shape, train: {0}, validation: {1}\".format(data_train2.shape, data_val2.shape)\n",
    "    print(log)\n",
    "    data_train2.dropna(how='any', inplace=True)\n",
    "    data_val2.dropna(how='any', inplace=True)\n",
    "    log = \"dist shape, train: {0}, validation: {1}\".format(data_train2.shape, data_val2.shape)\n",
    "    print(log)\n",
    "    \n",
    "    if balance == True:\n",
    "        log = \"data shape before balance: {0}\".format(data_train2.shape)\n",
    "        print(log)\n",
    "        data_train2 = data_balance(data_train2, str_type)\n",
    "        log = \"data shape after balance: {0}\".format(data_train2.shape)\n",
    "        print(log)\n",
    "        \n",
    "    # reset index\n",
    "    data_train2 = data_train2.reset_index(drop=True)\n",
    "    data_val2 = data_val2.reset_index(drop=True)\n",
    "    \n",
    "    # split data to AU ,pose, gaze, openpose\n",
    "    # train\n",
    "    data_au_train, data_pose_train, data_lmk_train, data_op_train, data_rn_train = split_data(data_train2)\n",
    "    # validation\n",
    "    data_au_val, data_pose_val, data_lmk_val, data_op_val, data_rn_val = split_data(data_val2)\n",
    "    \n",
    "    # str_type\n",
    "    if dir_features != None:\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_au.csv\"\n",
    "        data_au_train = substruct_features(data_au_train, file_f, str_type, window_time)\n",
    "        data_au_val = substruct_features(data_au_val, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_pose.csv\"\n",
    "        data_pose_train = substruct_features(data_pose_train, file_f, str_type, window_time)\n",
    "        data_pose_val = substruct_features(data_pose_val, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_lmk.csv\"\n",
    "        data_lmk_train = substruct_features(data_lmk_train, file_f, str_type, window_time)\n",
    "        data_lmk_val = substruct_features(data_lmk_val, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_op.csv\"\n",
    "        data_op_train = substruct_features(data_op_train, file_f, str_type, window_time)\n",
    "        data_op_val = substruct_features(data_op_val, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_rn.csv\"\n",
    "        data_rn_train = substruct_features(data_rn_train, file_f, str_type, window_time)\n",
    "        data_rn_val = substruct_features(data_rn_val, file_f, str_type, window_time)\n",
    "        \n",
    "    \n",
    "    # convert data(pandas) to time domain data(numpy) for lstm\n",
    "    ### *_y, *_group is the same value\n",
    "    # data au\n",
    "    np_au_x, np_au_y = make_dataset_for_gbm(data_au_train, str_type)\n",
    "    # data pose\n",
    "    np_pose_x, np_pose_y = make_dataset_for_gbm(data_pose_train, str_type)\n",
    "    # data lmk pca\n",
    "    np_lmk_x, np_lmk_y = make_dataset_for_gbm(data_lmk_train, str_type)\n",
    "    # data openpose\n",
    "    np_op_x, np_op_y = make_dataset_for_gbm(data_op_train, str_type)\n",
    "    # data resnet\n",
    "    np_rn_x, np_rn_y = make_dataset_for_gbm(data_rn_train, str_type)\n",
    "\n",
    "    # data au\n",
    "    np_au_x_val, np_au_y_val = make_dataset_for_gbm(data_au_val, str_type)\n",
    "    # data pose\n",
    "    np_pose_x_val, np_pose_y_val = make_dataset_for_gbm(data_pose_val, str_type)\n",
    "    # data lmk pca\n",
    "    np_lmk_x_val, np_lmk_y_val = make_dataset_for_gbm(data_lmk_val, str_type)\n",
    "    # data openpose\n",
    "    np_op_x_val, np_op_y_val = make_dataset_for_gbm(data_op_val, str_type)\n",
    "    # data resnet\n",
    "    np_rn_x_val, np_rn_y_val = make_dataset_for_gbm(data_rn_val, str_type)\n",
    "    \n",
    "    log = \" ***** finished Preprocessing ***** \"\n",
    "    print(log)\n",
    "    \n",
    "    # au\n",
    "    train_x = np_au_x\n",
    "    train_y = np_au_y.ravel()\n",
    "    val_x = np_au_x_val\n",
    "    val_y = np_au_y_val.ravel()\n",
    "    model_au, pred_train_au, pred_val_au, log_res_au = generate_sub_model(train_x, train_y, val_x, val_y, str_type)\n",
    "    \n",
    "    # head\n",
    "    train_x = np_pose_x\n",
    "    train_y = np_pose_y.ravel()\n",
    "    val_x = np_pose_x_val\n",
    "    val_y = np_pose_y_val.ravel()\n",
    "    model_pose, pred_train_pose, pred_val_pose, log_res_pose = generate_sub_model(train_x, train_y, val_x, val_y, str_type)\n",
    "    \n",
    "    # gaze\n",
    "    train_x = np_lmk_x\n",
    "    train_y = np_lmk_y.ravel()\n",
    "    val_x = np_lmk_x_val\n",
    "    val_y = np_lmk_y_val.ravel()\n",
    "    model_lmk, pred_train_lmk, pred_val_lmk, log_res_lmk = generate_sub_model(train_x, train_y, val_x, val_y, str_type)\n",
    "    \n",
    "    # openpose\n",
    "    train_x = np_op_x\n",
    "    train_y = np_op_y.ravel()\n",
    "    val_x = np_op_x_val\n",
    "    val_y = np_op_y_val.ravel()\n",
    "    model_op, pred_train_op, pred_val_op, log_res_op = generate_sub_model(train_x, train_y, val_x, val_y, str_type)\n",
    "    \n",
    "    # resnet\n",
    "    train_x = np_rn_x\n",
    "    train_y = np_rn_y.ravel()\n",
    "    val_x = np_rn_x_val\n",
    "    val_y = np_rn_y_val.ravel()\n",
    "    model_rn, pred_train_rn, pred_val_rn, log_res_rn = generate_sub_model(train_x, train_y, val_x, val_y, str_type)\n",
    "    \n",
    "    # data set for ensemble\n",
    "    # stacked predict data: train\n",
    "    stack_pred = np.column_stack((pred_train_au, pred_train_pose, pred_train_lmk, pred_train_op, pred_train_rn))\n",
    "\n",
    "    # stacked predict data: validation\n",
    "    stack_pred_val = np.column_stack((pred_val_au, pred_val_pose, pred_val_lmk, pred_val_op, pred_val_rn))\n",
    "\n",
    "    # generate single-term ensemble model\n",
    "    model_ens, pred_train_ens, pred_val_ens, log_res_ens = generate_sub_model(stack_pred, train_y, \n",
    "                                                                              stack_pred_val, val_y,\n",
    "                                                                              str_type)\n",
    "\n",
    "    # save models\n",
    "    # save model\n",
    "    f = dir_out + 'model_au' + str_footer + str_time + '.pickle'\n",
    "    with open(f, mode='wb') as fp:\n",
    "        pickle.dump(model_au, fp)\n",
    "    f = dir_out + 'model_pose' + str_footer + str_time + '.pickle'\n",
    "    with open(f, mode='wb') as fp:\n",
    "        pickle.dump(model_pose, fp)\n",
    "    f = dir_out + 'model_lmk' + str_footer + str_time + '.pickle'\n",
    "    with open(f, mode='wb') as fp:\n",
    "        pickle.dump(model_lmk, fp)\n",
    "    f = dir_out + 'model_op' + str_footer + str_time + '.pickle'\n",
    "    with open(f, mode='wb') as fp:\n",
    "        pickle.dump(model_op, fp)\n",
    "    f = dir_out + 'model_rn' + str_footer + str_time + '.pickle'\n",
    "    with open(f, mode='wb') as fp:\n",
    "        pickle.dump(model_rn, fp)\n",
    "    f = dir_out + 'model_ens' + str_footer + str_time + '.pickle'\n",
    "    with open(f, mode='wb') as fp:\n",
    "        pickle.dump(model_ens, fp)\n",
    "    \n",
    "    #save log\n",
    "    log_end = \"<au>: {0}\\n<head>: {1}\\n<gaze>: {2}\\n<pose>: {3}\\n<rn>: {4}\\n<ens>: {5}\".format(log_res_au, \n",
    "                                                    log_res_pose, log_res_lmk, log_res_op, log_res_rn, log_res_ens)\n",
    "    print(log_end)\n",
    "\n",
    "    file_result = dir_out + 'result' + str_footer + str_time + '.txt'\n",
    "    with open(file_result, mode='w') as f:\n",
    "        f.write(log_end)\n",
    "        \n",
    "    log = \"*** FINISHED *** Target type: {0}, time: {1}s\".format(str_type, window_time)\n",
    "    print(log)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
