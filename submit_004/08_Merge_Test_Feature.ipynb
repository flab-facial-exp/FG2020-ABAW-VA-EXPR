{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "merge openface, openpose, and label data per frame\n",
    " * based adjusted openface \"frame\" (openface data have multi-person and missing frame)\n",
    " * creating \"Training\", \"Validation\" subfolder in output folder\n",
    " * filename of openface: <vidoe name>.csv\n",
    " * filename of openpose: <vidoe name>_openpose.csv\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import datetime\n",
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root folder\n",
    "dir_submit = str(Path().resolve())\n",
    "dir_base = str(Path(Path().resolve()).parent) + \"\\\\base_data\"\n",
    "\n",
    "# openface, openpose, resnet folder\n",
    "dir_of = dir_base + \"\\\\OpenFace\\\\\"\n",
    "dir_op = dir_base + \"\\\\OpenPose\\\\\"\n",
    "dir_rn = dir_base + \"\\\\Resnet\\\\\"\n",
    "\n",
    "# VA, EXP test set name folder\n",
    "dir_test_set = dir_base + \"\\\\test_set\\\\\"\n",
    "\n",
    "# test set name file\n",
    "file_test_va = dir_test_set + \"va_test_set.txt\"\n",
    "file_test_exp = dir_test_set + \"expression_test_set.txt\"\n",
    "\n",
    "# input standardization parameter folder\n",
    "dir_norm = dir_base + \"\\\\Merged_with_resnet\\\\Norm\\\\\"\n",
    "\n",
    "# frame count folder  #sub \"AU\", \"VA\", \"EXP\" \n",
    "dir_count = dir_base + \"\\\\Frame_Count\\\\\"\n",
    "\n",
    "# output dataset folder\n",
    "dir_out_va = dir_base + \"\\\\Merged_with_resnet\\\\Merged_VA\\\\Test\\\\\"\n",
    "# create output folder\n",
    "if os.path.isdir(dir_out_va) == False:\n",
    "    os.makedirs(dir_out_va)\n",
    "\n",
    "dir_out_exp = dir_base + \"\\\\Merged_with_resnet\\\\Merged_EXP\\\\Test\\\\\"\n",
    "# create output folder\n",
    "if os.path.isdir(dir_out_exp) == False:\n",
    "    os.makedirs(dir_out_exp)\n",
    "\n",
    "# exclude file name (with out \"file_exc\") *exclude multi-person\n",
    "\n",
    "file_count = dir_count + \"*.csv\"\n",
    "files_count = [\n",
    "    filename for filename in sorted(glob.glob(file_count))\n",
    "]\n",
    "log = \"file number of count: {0}\".format(len(files_count))\n",
    "print(log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test name\n",
    "df_name_va = pd.read_csv(file_test_va, header=None)\n",
    "df_name_exp = pd.read_csv(file_test_exp, header=None)\n",
    "print(df_name_va)\n",
    "print(df_name_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate standardization parameter\n",
    "def get_standardize_param(dir_norm_param):\n",
    "    of_mean = pd.read_hdf(dir_norm_param + \"raw_mean_of.h5\",\"key\")\n",
    "    of_std = pd.read_hdf(dir_norm_param + \"raw_std_of.h5\",\"key\")\n",
    "    op_mean = pd.read_hdf(dir_norm_param + \"raw_mean_op.h5\",\"key\")\n",
    "    op_std = pd.read_hdf(dir_norm_param + \"raw_std_op.h5\",\"key\")\n",
    "    rn_mean = pd.read_hdf(dir_norm_param + \"raw_mean_rn.h5\",\"key\")\n",
    "    rn_std = pd.read_hdf(dir_norm_param + \"raw_std_rn.h5\",\"key\")\n",
    "    \n",
    "    \n",
    "    mean_data = of_mean.append(op_mean)\n",
    "    mean_data = mean_data.append(rn_mean)\n",
    "    mean_data = mean_data.reset_index()\n",
    "    std_data  = of_std.append(op_std)\n",
    "    std_data  = std_data.append(rn_std)\n",
    "    std_data = std_data.reset_index()\n",
    "    \n",
    "    \n",
    "    return mean_data, std_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_data, std_data = get_standardize_param(dir_norm)\n",
    "\n",
    "print(mean_data)\n",
    "print(std_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge openface, openpose and label\n",
    "def merge_of_data(data_names,dir_count, dir_of, dir_op, dir_rn, dir_out, param_mean, param_std, str_type):\n",
    "    count = 0\n",
    "    max_count = len(data_names)    \n",
    "    if len(data_names) <1:\n",
    "        print(\"test files name are not found\")\n",
    "        data_merge = pd.DataFrame()\n",
    "        return\n",
    "    \n",
    "    names = data_names.iloc[:,0].values\n",
    "\n",
    "    for name in names:\n",
    "        \n",
    "        # set save file mame\n",
    "        file_out = dir_out + name + \".h5\"\n",
    "\n",
    "        # read openface data, delete duplicated frame, set index based on \"frame\"\n",
    "        f_of = dir_of + name + \".csv\"\n",
    "        data_of = pd.read_csv(f_of)\n",
    "        data_of = data_of.drop_duplicates([\"frame\"])\n",
    "        \n",
    "        # read openpose data, delete duplicated frame, set frame column based on \"Unnamed: 0\"+1\n",
    "        f_op = dir_op + name + \"_openpose.csv\"\n",
    "        data_op = pd.read_csv(f_op)\n",
    "        data_op = data_op.drop_duplicates([\"Unnamed: 0\"])\n",
    "        data_op[\"frame\"] = data_op[\"Unnamed: 0\"]+1\n",
    "        \n",
    "        f_rn = dir_rn + name + \"_resnet50.h5\"\n",
    "        data_rn = pd.read_hdf(f_rn).iloc[:,0:201]\n",
    "               \n",
    "        f_count = dir_count + name + \".csv\"\n",
    "        data_count = pd.read_csv(f_count)\n",
    "        \n",
    "        # join data openface, openpose df_a.merge(df_b, on='mukey', how='left')\n",
    "        data_tmp = data_count.merge(data_of, on='frame', how='left')\n",
    "        data_tmp = data_tmp.merge(data_op, on='frame', how='left')\n",
    "        data_tmp = data_tmp.merge(data_rn, on='frame', how='left')\n",
    "        #data_tmp = data_tmp.fillna(0)\n",
    "        #data_tmp = data_tmp[data_tmp[\"frame\"]>0]\n",
    "        data_tmp = data_tmp.reset_index(drop=True)\n",
    "        #data_tmp[\"frame\"] = data_tmp.index + 1\n",
    "        \n",
    "        #print(data_tmp)\n",
    "        \n",
    "        # standardize *** \n",
    "        col_len = len(data_tmp.columns)\n",
    "        for col in range(col_len):\n",
    "            if (col >= 5) & (col <= 35):\n",
    "                data_tmp.iloc[:,col] = (data_tmp.iloc[:,col] - param_mean.iloc[col,1]) / param_std.iloc[col,1]\n",
    "            elif (col >= 56) & (col <= 130):\n",
    "                data_tmp.iloc[:,col] = (data_tmp.iloc[:,col] - param_mean.iloc[col,1]) / param_std.iloc[col,1]\n",
    "            elif (col >= 131):\n",
    "                data_tmp.iloc[:,col] = (data_tmp.iloc[:,col] - param_mean.iloc[col,1]) / param_std.iloc[col,1]\n",
    "        #data_of = (data_of - data_of.mean()) / data_x.std()\n",
    "        \n",
    "        #f_op = files_of[i].replace(\".csv\",\"\") + \"_openpose.csv\"\n",
    "        name_of = os.path.splitext(os.path.basename(f_of))[0]\n",
    "        name_op = os.path.splitext(os.path.basename(f_op))[0].replace(\"_openpose\", \"\")\n",
    "        name_rn = os.path.splitext(os.path.basename(f_rn))[0].replace(\"_resnet50\", \"\")\n",
    "        \n",
    "        # save merged file\n",
    "        #data_merge.to_csv(file_out, index=False, float_format='%.6g')\n",
    "        data_tmp.to_hdf(file_out, key='key', mode=\"w\", complevel=5, complib=\"lzo\")\n",
    "        log = \"{0}/{1}: {2}, {3}, {4}\".format(count+1, max_count, name_of, name_op, name_rn)\n",
    "        print(log)\n",
    "        count = count + 1\n",
    "        \n",
    "    log = \"** finished **\"\n",
    "    print(log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create and save merge data \"VA Test\"\n",
    "merge_of_data(df_name_va, dir_count, dir_of, dir_op, dir_rn, dir_out_va, mean_data, std_data, \"VA\")\n",
    "\n",
    "# create and save merge data \"EXP Test\"\n",
    "merge_of_data(df_name_exp, dir_count, dir_of, dir_op, dir_rn, dir_out_exp, mean_data, std_data, \"EXP\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
