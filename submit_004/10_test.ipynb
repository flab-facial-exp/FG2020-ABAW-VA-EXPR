{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "evaluate multi time-window model taht is fusion model of multi target models\n",
    " * select type: \"EXP\", \"VA_V\", \"VA_A\"\n",
    " * select sub1, sub2 type: \"EXP\", \"VA_V\", \"VA_A\"\n",
    " * evaluate validation per frame\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import sklearn #機械学習のライブラリ\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score,mean_squared_error,f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean, median,variance,stdev\n",
    "import math\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(file_model):\n",
    "    with open(file_model, mode='rb') as fp:\n",
    "        model = pickle.load(fp)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_models(dir_model, str_type, window_time):\n",
    "    ext = \"_{0}s.pickle\".format(str(window_time).zfill(2))\n",
    "    \n",
    "    model_au = load_model(dir_model + \"model_au_gbm_\" + str_type + ext)\n",
    "    model_pose = load_model(dir_model + \"model_pose_gbm_\" + str_type + ext)\n",
    "    model_lmk = load_model(dir_model + \"model_lmk_gbm_\" + str_type + ext)\n",
    "    model_op = load_model(dir_model + \"model_op_gbm_\" + str_type + ext)\n",
    "    model_rn = load_model(dir_model + \"model_rn_gbm_\" + str_type + ext)\n",
    "    model_ens = load_model(dir_model + \"model_ens_gbm_\" + str_type + ext)\n",
    "    \n",
    "    models = [model_au, model_pose, model_lmk, model_op, model_rn, model_ens]\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load & adjust features\n",
    "def adjust_features(file_name, str_time):\n",
    "    # meake file name without ext\n",
    "    name = os.path.splitext(os.path.basename(file_name))[0].replace(str_time,'')\n",
    "    # read file\n",
    "    data = pd.read_hdf(file_name)\n",
    "    # drop non-used features\n",
    "    data = data.drop(['frame-avg',' face_id-avg',' timestamp-avg',' confidence-avg',' success-avg',\n",
    "                              'frame-std',' face_id-std',' timestamp-std',' confidence-std',' success-std',\n",
    "                              'frame-range', ' face_id-range', ' timestamp-range', ' confidence-range', ' success-range',\n",
    "                              'frame-slope', ' face_id-slope', ' timestamp-slope', ' confidence-slope', ' success-slope',\n",
    "                              'Unnamed: 0-avg', 'Unnamed: 0-std', 'Unnamed: 0-range', 'Unnamed: 0-slope'\n",
    "                               ], axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split base data to <au>, <gaze and pose>, <eye_landmark, 2d landmark, 3d landmark>\n",
    "# ** 'count','label','subject' is contained in all splits\n",
    "def split_data(in_data):\n",
    "    # au data\n",
    "    df_au = in_data.loc[:, in_data.columns.str.contains(\"AU\") ]\n",
    "    #df_au = df_au.join(df_lable)\n",
    "    #print(\"AU data shape: \",df_au.shape)\n",
    "\n",
    "    # gaze and pose data **** temp pose\n",
    "    df_pose = in_data.loc[:, in_data.columns.str.contains(\"pose_\") ]\n",
    "    #df_pose = df_pose.join(df_lable)\n",
    "    #print(\"Gaze & Pose data shape: \",df_pose.shape)\n",
    "    \n",
    "    # eye_landmark, 2d landmark, 3d landmark data **** temp gaze\n",
    "    df_lmk = in_data.loc[:, in_data.columns.str.contains(\"gaze\")]\n",
    "    #df_lmk = df_lmk.join(df_lable)\n",
    "    #print(\"Landmark data shape: \",df_lmk.shape)\n",
    "    \n",
    "    # openpose\n",
    "    #df_op = in_data.loc[:, ~in_data.columns.str.contains(\"AU|pose_|gaze\")]\n",
    "    df_op = in_data.loc[:, in_data.columns.str.contains(\"hand_flag|0x|0y|0c|1x|1y|1c|2x|2y|2c|3x|3y|3c|4x|4y|4c|5x|5y|5c|6x|6y|6c|7x|7y|7c|8x|8y|8c|9x|9y|9c|10x|10y|10c|11x|11y|11c|12x|12y|12c|13x|13y|13c|14x|14y|14c|15x|15y|15c|16x|16y|16c|17x|17y|17c|18x|18y|18c|19x|19y|19c|20x|20y|20c|21x|21y|21c|22x|22y|22c|23x|23y|23c|24x|24y|24c\")]\n",
    "    #print(\"Opepose data shape: \",df_op.shape)\n",
    "    \n",
    "    # resnet\n",
    "    df_rn = in_data.loc[:, ~in_data.columns.str.contains(\"AU|pose_|gaze|hand_flag|0x|0y|0c|1x|1y|1c|2x|2y|2c|3x|3y|3c|4x|4y|4c|5x|5y|5c|6x|6y|6c|7x|7y|7c|8x|8y|8c|9x|9y|9c|10x|10y|10c|11x|11y|11c|12x|12y|12c|13x|13y|13c|14x|14y|14c|15x|15y|15c|16x|16y|16c|17x|17y|17c|18x|18y|18c|19x|19y|19c|20x|20y|20c|21x|21y|21c|22x|22y|22c|23x|23y|23c|24x|24y|24c\")]\n",
    "    #print(\"Resnet data shape: \",df_rn.shape)\n",
    "    \n",
    "    \"\"\"\n",
    "    np_au = df_au.values\n",
    "    np_pose = df_pose.values\n",
    "    np_lmk = df_lmk.values\n",
    "    np_op = df_op.values\n",
    "    np_rn = df_rn.values    \n",
    "    \"\"\"\n",
    "    #print(\"** end **\")\n",
    "    return df_au, df_pose, df_lmk, df_op, df_rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_VA_A(file_name_01s, file_name_06s, file_name_12s, file_name_03s, dir_features = None):\n",
    "\n",
    "    # VA_A\n",
    "    # 01s\n",
    "    str_time = \"_01s\"\n",
    "    f = file_name_01s\n",
    "\n",
    "    data = adjust_features(f, str_time)\n",
    "    df_au, df_pose, df_lmk, df_op, df_rn = split_data(data)\n",
    "    #np_au, np_pose, np_lmk, np_op, np_rn = split_data_np(data)\n",
    "    \n",
    "    str_type = \"VA_A\"\n",
    "    window_time = 1\n",
    "    if dir_features != None:\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_au.csv\"\n",
    "        df_au = substruct_features(df_au, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_pose.csv\"\n",
    "        df_pose = substruct_features(df_pose, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_lmk.csv\"\n",
    "        df_lmk = substruct_features(df_lmk, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_op.csv\"\n",
    "        df_op = substruct_features(df_op, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_rn.csv\"\n",
    "        df_rn = substruct_features(df_rn, file_f, str_type, window_time)\n",
    "    np_au = df_au.values\n",
    "    np_pose = df_pose.values\n",
    "    np_lmk = df_lmk.values\n",
    "    np_op = df_op.values\n",
    "    np_rn = df_rn.values \n",
    "\n",
    "    pred_au = model_VA_A_01s[0].predict(np_au).ravel()\n",
    "    pred_pose = model_VA_A_01s[1].predict(np_pose).ravel()\n",
    "    pred_lmk = model_VA_A_01s[2].predict(np_lmk).ravel()\n",
    "    pred_op = model_VA_A_01s[3].predict(np_op).ravel()\n",
    "    pred_rn = model_VA_A_01s[4].predict(np_rn).ravel()\n",
    "    stack_ens = np.column_stack((pred_au, pred_pose, pred_lmk, pred_op, pred_rn))\n",
    "    pred_ens_VA_A_01s = model_VA_A_01s[5].predict(stack_ens).ravel()\n",
    "\n",
    "    # 06s\n",
    "    str_time = \"_06s\"\n",
    "    f = file_name_06s\n",
    "\n",
    "    data = adjust_features(f, str_time)\n",
    "    df_au, df_pose, df_lmk, df_op, df_rn = split_data(data)\n",
    "    #np_au, np_pose, np_lmk, np_op, np_rn = split_data_np(data)\n",
    "    \n",
    "    str_type = \"VA_A\"\n",
    "    window_time = 6\n",
    "    if dir_features != None:\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_au.csv\"\n",
    "        df_au = substruct_features(df_au, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_pose.csv\"\n",
    "        df_pose = substruct_features(df_pose, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_lmk.csv\"\n",
    "        df_lmk = substruct_features(df_lmk, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_op.csv\"\n",
    "        df_op = substruct_features(df_op, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_rn.csv\"\n",
    "        df_rn = substruct_features(df_rn, file_f, str_type, window_time)\n",
    "    np_au = df_au.values\n",
    "    np_pose = df_pose.values\n",
    "    np_lmk = df_lmk.values\n",
    "    np_op = df_op.values\n",
    "    np_rn = df_rn.values \n",
    "\n",
    "    pred_au = model_VA_A_06s[0].predict(np_au).ravel()\n",
    "    pred_pose = model_VA_A_06s[1].predict(np_pose).ravel()\n",
    "    pred_lmk = model_VA_A_06s[2].predict(np_lmk).ravel()\n",
    "    pred_op = model_VA_A_06s[3].predict(np_op).ravel()\n",
    "    pred_rn = model_VA_A_06s[4].predict(np_rn).ravel()\n",
    "    stack_ens = np.column_stack((pred_au, pred_pose, pred_lmk, pred_op, pred_rn))\n",
    "    pred_ens_VA_A_06s = model_VA_A_06s[5].predict(stack_ens).ravel()\n",
    "\n",
    "    # 12s\n",
    "    str_time = \"_12s\"\n",
    "    f = file_name_12s\n",
    "\n",
    "    data = adjust_features(f, str_time)\n",
    "    df_au, df_pose, df_lmk, df_op, df_rn = split_data(data)\n",
    "    #np_au, np_pose, np_lmk, np_op, np_rn = split_data_np(data)\n",
    "    \n",
    "    str_type = \"VA_A\"\n",
    "    window_time = 12\n",
    "    if dir_features != None:\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_au.csv\"\n",
    "        df_au = substruct_features(df_au, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_pose.csv\"\n",
    "        df_pose = substruct_features(df_pose, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_lmk.csv\"\n",
    "        df_lmk = substruct_features(df_lmk, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_op.csv\"\n",
    "        df_op = substruct_features(df_op, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_rn.csv\"\n",
    "        df_rn = substruct_features(df_rn, file_f, str_type, window_time)\n",
    "    np_au = df_au.values\n",
    "    np_pose = df_pose.values\n",
    "    np_lmk = df_lmk.values\n",
    "    np_op = df_op.values\n",
    "    np_rn = df_rn.values \n",
    "\n",
    "    pred_au = model_VA_A_12s[0].predict(np_au).ravel()\n",
    "    pred_pose = model_VA_A_12s[1].predict(np_pose).ravel()\n",
    "    pred_lmk = model_VA_A_12s[2].predict(np_lmk).ravel()\n",
    "    pred_op = model_VA_A_12s[3].predict(np_op).ravel()\n",
    "    pred_rn = model_VA_A_12s[4].predict(np_rn).ravel()\n",
    "    stack_ens = np.column_stack((pred_au, pred_pose, pred_lmk, pred_op, pred_rn))\n",
    "    pred_ens_VA_A_12s = model_VA_A_12s[5].predict(stack_ens).ravel()\n",
    "    \n",
    "    # 3s\n",
    "    str_time = \"_03s\"\n",
    "    f = file_name_03s\n",
    "\n",
    "    data = adjust_features(f, str_time)\n",
    "    df_au, df_pose, df_lmk, df_op, df_rn = split_data(data)\n",
    "    #np_au, np_pose, np_lmk, np_op, np_rn = split_data_np(data)\n",
    "    \n",
    "    str_type = \"VA_A\"\n",
    "    window_time = 3\n",
    "    if dir_features != None:\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_au.csv\"\n",
    "        df_au = substruct_features(df_au, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_pose.csv\"\n",
    "        df_pose = substruct_features(df_pose, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_lmk.csv\"\n",
    "        df_lmk = substruct_features(df_lmk, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_op.csv\"\n",
    "        df_op = substruct_features(df_op, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_rn.csv\"\n",
    "        df_rn = substruct_features(df_rn, file_f, str_type, window_time)\n",
    "    np_au = df_au.values\n",
    "    np_pose = df_pose.values\n",
    "    np_lmk = df_lmk.values\n",
    "    np_op = df_op.values\n",
    "    np_rn = df_rn.values \n",
    "\n",
    "    pred_au = model_VA_A_03s[0].predict(np_au).ravel()\n",
    "    pred_pose = model_VA_A_03s[1].predict(np_pose).ravel()\n",
    "    pred_lmk = model_VA_A_03s[2].predict(np_lmk).ravel()\n",
    "    pred_op = model_VA_A_03s[3].predict(np_op).ravel()\n",
    "    pred_rn = model_VA_A_03s[4].predict(np_rn).ravel()\n",
    "    stack_ens = np.column_stack((pred_au, pred_pose, pred_lmk, pred_op, pred_rn))\n",
    "    pred_ens_VA_A_03s = model_VA_A_03s[5].predict(stack_ens).ravel()\n",
    "\n",
    "    # ensemble: single task \n",
    "    stack_ens = np.column_stack((pred_ens_VA_A_01s, pred_ens_VA_A_06s, pred_ens_VA_A_12s, pred_ens_VA_A_03s))\n",
    "    pred_VA_A_single = model_VA_A_single.predict(stack_ens).ravel()\n",
    "\n",
    "    return pred_ens_VA_A_01s, pred_ens_VA_A_06s, pred_ens_VA_A_12s, pred_ens_VA_A_03s, pred_VA_A_single\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_VA_V(file_name_01s, file_name_06s, file_name_12s, file_name_03s, dir_features = None):\n",
    "\n",
    "    # VA_V\n",
    "    # 01s\n",
    "    str_time = \"_01s\"\n",
    "    f = file_name_01s\n",
    "\n",
    "    data = adjust_features(f, str_time)\n",
    "    df_au, df_pose, df_lmk, df_op, df_rn = split_data(data)\n",
    "    #np_au, np_pose, np_lmk, np_op, np_rn = split_data_np(data)\n",
    "    \n",
    "    str_type = \"VA_V\"\n",
    "    window_time = 1\n",
    "    if dir_features != None:\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_au.csv\"\n",
    "        df_au = substruct_features(df_au, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_pose.csv\"\n",
    "        df_pose = substruct_features(df_pose, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_lmk.csv\"\n",
    "        df_lmk = substruct_features(df_lmk, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_op.csv\"\n",
    "        df_op = substruct_features(df_op, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_rn.csv\"\n",
    "        df_rn = substruct_features(df_rn, file_f, str_type, window_time)\n",
    "    np_au = df_au.values\n",
    "    np_pose = df_pose.values\n",
    "    np_lmk = df_lmk.values\n",
    "    np_op = df_op.values\n",
    "    np_rn = df_rn.values \n",
    "\n",
    "    pred_au = model_VA_V_01s[0].predict(np_au).ravel()\n",
    "    pred_pose = model_VA_V_01s[1].predict(np_pose).ravel()\n",
    "    pred_lmk = model_VA_V_01s[2].predict(np_lmk).ravel()\n",
    "    pred_op = model_VA_V_01s[3].predict(np_op).ravel()\n",
    "    pred_rn = model_VA_V_01s[4].predict(np_rn).ravel()\n",
    "    stack_ens = np.column_stack((pred_au, pred_pose, pred_lmk, pred_op, pred_rn))\n",
    "    pred_ens_VA_V_01s = model_VA_V_01s[5].predict(stack_ens).ravel()\n",
    "\n",
    "    # 06s\n",
    "    str_time = \"_06s\"\n",
    "    f = file_name_06s\n",
    "\n",
    "    data = adjust_features(f, str_time)\n",
    "    df_au, df_pose, df_lmk, df_op, df_rn = split_data(data)\n",
    "    #np_au, np_pose, np_lmk, np_op, np_rn = split_data_np(data)\n",
    "    \n",
    "    str_type = \"VA_V\"\n",
    "    window_time = 6\n",
    "    if dir_features != None:\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_au.csv\"\n",
    "        df_au = substruct_features(df_au, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_pose.csv\"\n",
    "        df_pose = substruct_features(df_pose, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_lmk.csv\"\n",
    "        df_lmk = substruct_features(df_lmk, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_op.csv\"\n",
    "        df_op = substruct_features(df_op, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_rn.csv\"\n",
    "        df_rn = substruct_features(df_rn, file_f, str_type, window_time)\n",
    "    np_au = df_au.values\n",
    "    np_pose = df_pose.values\n",
    "    np_lmk = df_lmk.values\n",
    "    np_op = df_op.values\n",
    "    np_rn = df_rn.values \n",
    "\n",
    "    pred_au = model_VA_V_06s[0].predict(np_au).ravel()\n",
    "    pred_pose = model_VA_V_06s[1].predict(np_pose).ravel()\n",
    "    pred_lmk = model_VA_V_06s[2].predict(np_lmk).ravel()\n",
    "    pred_op = model_VA_V_06s[3].predict(np_op).ravel()\n",
    "    pred_rn = model_VA_V_06s[4].predict(np_rn).ravel()\n",
    "    stack_ens = np.column_stack((pred_au, pred_pose, pred_lmk, pred_op, pred_rn))\n",
    "    pred_ens_VA_V_06s = model_VA_V_06s[5].predict(stack_ens).ravel()\n",
    "\n",
    "    # 12s\n",
    "    str_time = \"_12s\"\n",
    "    f = file_name_12s\n",
    "\n",
    "    data = adjust_features(f, str_time)\n",
    "    df_au, df_pose, df_lmk, df_op, df_rn = split_data(data)\n",
    "    #np_au, np_pose, np_lmk, np_op, np_rn = split_data_np(data)\n",
    "    \n",
    "    str_type = \"VA_V\"\n",
    "    window_time = 12\n",
    "    if dir_features != None:\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_au.csv\"\n",
    "        df_au = substruct_features(df_au, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_pose.csv\"\n",
    "        df_pose = substruct_features(df_pose, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_lmk.csv\"\n",
    "        df_lmk = substruct_features(df_lmk, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_op.csv\"\n",
    "        df_op = substruct_features(df_op, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_rn.csv\"\n",
    "        df_rn = substruct_features(df_rn, file_f, str_type, window_time)\n",
    "    np_au = df_au.values\n",
    "    np_pose = df_pose.values\n",
    "    np_lmk = df_lmk.values\n",
    "    np_op = df_op.values\n",
    "    np_rn = df_rn.values \n",
    "    \n",
    "    pred_au = model_VA_V_12s[0].predict(np_au).ravel()\n",
    "    pred_pose = model_VA_V_12s[1].predict(np_pose).ravel()\n",
    "    pred_lmk = model_VA_V_12s[2].predict(np_lmk).ravel()\n",
    "    pred_op = model_VA_V_12s[3].predict(np_op).ravel()\n",
    "    pred_rn = model_VA_V_12s[4].predict(np_rn).ravel()\n",
    "    stack_ens = np.column_stack((pred_au, pred_pose, pred_lmk, pred_op, pred_rn))\n",
    "    pred_ens_VA_V_12s = model_VA_V_12s[5].predict(stack_ens).ravel()\n",
    "    \n",
    "    # 03s\n",
    "    str_time = \"_03s\"\n",
    "    f = file_name_03s\n",
    "\n",
    "    data = adjust_features(f, str_time)\n",
    "    df_au, df_pose, df_lmk, df_op, df_rn = split_data(data)\n",
    "    #np_au, np_pose, np_lmk, np_op, np_rn = split_data_np(data)\n",
    "    \n",
    "    str_type = \"VA_V\"\n",
    "    window_time = 3\n",
    "    if dir_features != None:\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_au.csv\"\n",
    "        df_au = substruct_features(df_au, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_pose.csv\"\n",
    "        df_pose = substruct_features(df_pose, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_lmk.csv\"\n",
    "        df_lmk = substruct_features(df_lmk, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_op.csv\"\n",
    "        df_op = substruct_features(df_op, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_rn.csv\"\n",
    "        df_rn = substruct_features(df_rn, file_f, str_type, window_time)\n",
    "    np_au = df_au.values\n",
    "    np_pose = df_pose.values\n",
    "    np_lmk = df_lmk.values\n",
    "    np_op = df_op.values\n",
    "    np_rn = df_rn.values \n",
    "    \n",
    "    pred_au = model_VA_V_03s[0].predict(np_au).ravel()\n",
    "    pred_pose = model_VA_V_03s[1].predict(np_pose).ravel()\n",
    "    pred_lmk = model_VA_V_03s[2].predict(np_lmk).ravel()\n",
    "    pred_op = model_VA_V_03s[3].predict(np_op).ravel()\n",
    "    pred_rn = model_VA_V_03s[4].predict(np_rn).ravel()\n",
    "    stack_ens = np.column_stack((pred_au, pred_pose, pred_lmk, pred_op, pred_rn))\n",
    "    pred_ens_VA_V_03s = model_VA_V_03s[5].predict(stack_ens).ravel()\n",
    "\n",
    "    # ensemble: single task \n",
    "    stack_ens = np.column_stack((pred_ens_VA_V_01s, pred_ens_VA_V_06s, pred_ens_VA_V_12s, pred_ens_VA_V_03s))\n",
    "    pred_VA_V_single = model_VA_V_single.predict(stack_ens).ravel()\n",
    "\n",
    "    return pred_ens_VA_V_01s, pred_ens_VA_V_06s, pred_ens_VA_V_12s, pred_ens_VA_V_03s, pred_VA_V_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_EXP(file_name_01s, file_name_06s, file_name_12s, file_name_03s, dir_features = None):\n",
    "\n",
    "    # EXP\n",
    "    # 01s\n",
    "    str_time = \"_01s\"\n",
    "    f = file_name_01s\n",
    "\n",
    "    data = adjust_features(f, str_time)\n",
    "    df_au, df_pose, df_lmk, df_op, df_rn = split_data(data)\n",
    "    #np_au, np_pose, np_lmk, np_op, np_rn = split_data_np(data)\n",
    "    \n",
    "    str_type = \"EXP\"\n",
    "    window_time = 1\n",
    "    if dir_features != None:\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_au.csv\"\n",
    "        df_au = substruct_features(df_au, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_pose.csv\"\n",
    "        df_pose = substruct_features(df_pose, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_lmk.csv\"\n",
    "        df_lmk = substruct_features(df_lmk, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_op.csv\"\n",
    "        df_op = substruct_features(df_op, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_rn.csv\"\n",
    "        df_rn = substruct_features(df_rn, file_f, str_type, window_time)\n",
    "    np_au = df_au.values\n",
    "    np_pose = df_pose.values\n",
    "    np_lmk = df_lmk.values\n",
    "    np_op = df_op.values\n",
    "    np_rn = df_rn.values \n",
    "\n",
    "    pred_au = model_EXP_01s[0].predict(np_au)\n",
    "    pred_pose = model_EXP_01s[1].predict(np_pose)\n",
    "    pred_lmk = model_EXP_01s[2].predict(np_lmk)\n",
    "    pred_op = model_EXP_01s[3].predict(np_op)\n",
    "    pred_rn = model_EXP_01s[4].predict(np_rn)\n",
    "    stack_ens = np.column_stack((pred_au, pred_pose, pred_lmk, pred_op, pred_rn))\n",
    "    pred_ens_EXP_01s = model_EXP_01s[5].predict(stack_ens)\n",
    "\n",
    "    # 06s\n",
    "    str_time = \"_06s\"\n",
    "    f = file_name_06s\n",
    "\n",
    "    data = adjust_features(f, str_time)\n",
    "    df_au, df_pose, df_lmk, df_op, df_rn = split_data(data)\n",
    "    #np_au, np_pose, np_lmk, np_op, np_rn = split_data_np(data)\n",
    "    \n",
    "    str_type = \"EXP\"\n",
    "    window_time = 6\n",
    "    if dir_features != None:\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_au.csv\"\n",
    "        df_au = substruct_features(df_au, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_pose.csv\"\n",
    "        df_pose = substruct_features(df_pose, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_lmk.csv\"\n",
    "        df_lmk = substruct_features(df_lmk, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_op.csv\"\n",
    "        df_op = substruct_features(df_op, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_rn.csv\"\n",
    "        df_rn = substruct_features(df_rn, file_f, str_type, window_time)\n",
    "    np_au = df_au.values\n",
    "    np_pose = df_pose.values\n",
    "    np_lmk = df_lmk.values\n",
    "    np_op = df_op.values\n",
    "    np_rn = df_rn.values \n",
    "\n",
    "    pred_au = model_EXP_06s[0].predict(np_au)\n",
    "    pred_pose = model_EXP_06s[1].predict(np_pose)\n",
    "    pred_lmk = model_EXP_06s[2].predict(np_lmk)\n",
    "    pred_op = model_EXP_06s[3].predict(np_op)\n",
    "    pred_rn = model_EXP_06s[4].predict(np_rn)\n",
    "    stack_ens = np.column_stack((pred_au, pred_pose, pred_lmk, pred_op, pred_rn))\n",
    "    pred_ens_EXP_06s = model_EXP_06s[5].predict(stack_ens)\n",
    "\n",
    "    # 12s\n",
    "    str_time = \"_12s\"\n",
    "    f = file_name_12s\n",
    "\n",
    "    data = adjust_features(f, str_time)\n",
    "    df_au, df_pose, df_lmk, df_op, df_rn = split_data(data)\n",
    "    #np_au, np_pose, np_lmk, np_op, np_rn = split_data_np(data)\n",
    "    \n",
    "    str_type = \"EXP\"\n",
    "    window_time = 12\n",
    "    if dir_features != None:\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_au.csv\"\n",
    "        df_au = substruct_features(df_au, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_pose.csv\"\n",
    "        df_pose = substruct_features(df_pose, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_lmk.csv\"\n",
    "        df_lmk = substruct_features(df_lmk, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_op.csv\"\n",
    "        df_op = substruct_features(df_op, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_rn.csv\"\n",
    "        df_rn = substruct_features(df_rn, file_f, str_type, window_time)\n",
    "    np_au = df_au.values\n",
    "    np_pose = df_pose.values\n",
    "    np_lmk = df_lmk.values\n",
    "    np_op = df_op.values\n",
    "    np_rn = df_rn.values \n",
    "\n",
    "    pred_au = model_EXP_12s[0].predict(np_au)\n",
    "    pred_pose = model_EXP_12s[1].predict(np_pose)\n",
    "    pred_lmk = model_EXP_12s[2].predict(np_lmk)\n",
    "    pred_op = model_EXP_12s[3].predict(np_op)\n",
    "    pred_rn = model_EXP_12s[4].predict(np_rn)\n",
    "    stack_ens = np.column_stack((pred_au, pred_pose, pred_lmk, pred_op, pred_rn))\n",
    "    pred_ens_EXP_12s = model_EXP_12s[5].predict(stack_ens)\n",
    "    \n",
    "    # 03s\n",
    "    str_time = \"_03s\"\n",
    "    f = file_name_03s\n",
    "\n",
    "    data = adjust_features(f, str_time)\n",
    "    df_au, df_pose, df_lmk, df_op, df_rn = split_data(data)\n",
    "    #np_au, np_pose, np_lmk, np_op, np_rn = split_data_np(data)\n",
    "    \n",
    "    str_type = \"EXP\"\n",
    "    window_time = 3\n",
    "    if dir_features != None:\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_au.csv\"\n",
    "        df_au = substruct_features(df_au, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_pose.csv\"\n",
    "        df_pose = substruct_features(df_pose, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_lmk.csv\"\n",
    "        df_lmk = substruct_features(df_lmk, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_op.csv\"\n",
    "        df_op = substruct_features(df_op, file_f, str_type, window_time)\n",
    "        file_f = dir_features + \"features_\" + str_type +\"_rn.csv\"\n",
    "        df_rn = substruct_features(df_rn, file_f, str_type, window_time)\n",
    "    np_au = df_au.values\n",
    "    np_pose = df_pose.values\n",
    "    np_lmk = df_lmk.values\n",
    "    np_op = df_op.values\n",
    "    np_rn = df_rn.values \n",
    "\n",
    "    pred_au = model_EXP_03s[0].predict(np_au)\n",
    "    pred_pose = model_EXP_03s[1].predict(np_pose)\n",
    "    pred_lmk = model_EXP_03s[2].predict(np_lmk)\n",
    "    pred_op = model_EXP_03s[3].predict(np_op)\n",
    "    pred_rn = model_EXP_03s[4].predict(np_rn)\n",
    "    stack_ens = np.column_stack((pred_au, pred_pose, pred_lmk, pred_op, pred_rn))\n",
    "    pred_ens_EXP_03s = model_EXP_03s[5].predict(stack_ens)\n",
    "\n",
    "    # ensemble: single task \n",
    "    stack_ens = np.column_stack((pred_ens_EXP_01s, pred_ens_EXP_06s, pred_ens_EXP_12s, pred_ens_EXP_03s))\n",
    "    pred_EXP_single = model_EXP_single.predict(stack_ens)\n",
    "\n",
    "    return pred_ens_EXP_01s, pred_ens_EXP_06s, pred_ens_EXP_12s, pred_ens_EXP_03s, pred_EXP_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multi_VA_A(file_name_01s, file_name_06s, file_name_12s, file_name_03s, dir_feature):\n",
    "\n",
    "    pred_ens_VA_A_01s, pred_ens_VA_A_06s, pred_ens_VA_A_12s, pred_ens_VA_A_03s, pred_VA_A_single = predict_single_VA_A(file_name_01s, file_name_06s, \n",
    "                                                                                                    file_name_12s, file_name_03s, dir_feature)\n",
    "    pred_ens_VA_V_01s, pred_ens_VA_V_06s, pred_ens_VA_V_12s, pred_ens_VA_V_03s, pred_VA_V_single = predict_single_VA_V(file_name_01s, file_name_06s,\n",
    "                                                                                                    file_name_12s, file_name_03s, dir_feature)\n",
    "    pred_ens_EXP_01s, pred_ens_EXP_06s, pred_ens_EXP_12s, pred_ens_EXP_03s, pred_EXP_single = predict_single_EXP(file_name_01s, file_name_06s, \n",
    "                                                                                               file_name_12s, file_name_03s, dir_feature)\n",
    "    \n",
    "    stack_ens = np.column_stack((pred_ens_VA_A_01s, pred_ens_VA_A_06s, pred_ens_VA_A_12s, pred_ens_VA_A_03s,\n",
    "                                 pred_VA_V_single, pred_EXP_single))\n",
    "    pred_VA_A_multi = model_VA_A_multi.predict(stack_ens).ravel()\n",
    "    \n",
    "    return pred_VA_A_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multi_VA_V(file_name_01s, file_name_06s, file_name_12s, file_name_03s, dir_feature):\n",
    "\n",
    "    pred_ens_VA_A_01s, pred_ens_VA_A_06s, pred_ens_VA_A_12s, pred_ens_VA_A_03s, pred_VA_A_single = predict_single_VA_A(file_name_01s, file_name_06s, \n",
    "                                                                                                    file_name_12s, file_name_03s, dir_feature)\n",
    "    pred_ens_VA_V_01s, pred_ens_VA_V_06s, pred_ens_VA_V_12s, pred_ens_VA_V_03s, pred_VA_V_single = predict_single_VA_V(file_name_01s, file_name_06s, \n",
    "                                                                                                    file_name_12s, file_name_03s, dir_feature)\n",
    "    pred_ens_EXP_01s, pred_ens_EXP_06s, pred_ens_EXP_12s, pred_ens_EXP_03s, pred_EXP_single = predict_single_EXP(file_name_01s, file_name_06s, \n",
    "                                                                                               file_name_12s, file_name_03s, dir_feature)\n",
    "    \n",
    "    stack_ens = np.column_stack((pred_ens_VA_V_01s, pred_ens_VA_V_06s, pred_ens_VA_V_12s, pred_ens_VA_V_03s,\n",
    "                                 pred_VA_A_single, pred_EXP_single))\n",
    "    pred_VA_V_multi = model_VA_V_multi.predict(stack_ens).ravel()\n",
    "    \n",
    "    return pred_VA_V_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multi_EXP(file_name_01s, file_name_06s, file_name_12s, file_name_03s, dir_feature):\n",
    "\n",
    "    pred_ens_VA_A_01s, pred_ens_VA_A_06s, pred_ens_VA_A_12s, pred_ens_VA_A_03s, pred_VA_A_single = predict_single_VA_A(file_name_01s, file_name_06s, \n",
    "                                                                                                    file_name_12s, file_name_03s, dir_feature)\n",
    "    pred_ens_VA_V_01s, pred_ens_VA_V_06s, pred_ens_VA_V_12s, pred_ens_VA_V_03s, pred_VA_V_single = predict_single_VA_V(file_name_01s, file_name_06s, \n",
    "                                                                                                    file_name_12s, file_name_03s, dir_feature)\n",
    "    pred_ens_EXP_01s, pred_ens_EXP_06s, pred_ens_EXP_12s, pred_ens_EXP_03s, pred_EXP_single = predict_single_EXP(file_name_01s, file_name_06s, \n",
    "                                                                                               file_name_12s, file_name_03s, dir_feature)\n",
    "    \n",
    "    stack_ens = np.column_stack((pred_ens_EXP_01s, pred_ens_EXP_06s, pred_ens_EXP_12s, pred_ens_EXP_03s,\n",
    "                                 pred_VA_A_single, pred_VA_V_single))\n",
    "    pred_EXP_multi_tmp1 = model_EXP_multi.predict(stack_ens)\n",
    "    \n",
    "    pred_EXP_multi_tmp2 = np.argmax(pred_EXP_multi_tmp1, axis=1) # 一番大きい予測確率のクラスを予測クラスに\n",
    "    \n",
    "    pred_EXP_multi = pred_EXP_multi_tmp2.ravel()\n",
    "    \n",
    "    return pred_EXP_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substruct_features(data, fp, str_type, window_time):\n",
    "    col = str(window_time).zfill(2) + \"s\"\n",
    "    data_f = pd.read_csv(fp)\n",
    "    \n",
    "    if str_type == \"EXP\":\n",
    "        list_f = list(data_f[col].values.ravel())\n",
    "        #list_f = np.append(list_f, [\"count\", \"subject\", \"Neutral-avg\"])\n",
    "    else:\n",
    "        list_f = list(data_f[col].values.ravel())\n",
    "        #list_f = np.append(list_f, [\"count\", \"subject\", \"valence-avg\", \"arousal-avg\"])\n",
    "    \n",
    "    data2 = data[list_f]\n",
    "    \n",
    "    return data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# root folder\n",
    "dir_submit = str(Path().resolve())\n",
    "dir_base = str(Path(Path().resolve()).parent) + \"\\\\base_data\"\n",
    "\n",
    "# merged data folder (va, exp : train, validation)\n",
    "dir_test_exp = dir_base + \"\\\\Merged_with_resnet\\\\Merged_EXP_roll\\\\Test\\\\\"\n",
    "dir_test_va = dir_base + \"\\\\Merged_with_resnet\\\\Merged_VA_roll\\\\Test\\\\\"\n",
    "\n",
    "# set model folder: 01, 06, 12s window\n",
    "dir_model_01s = dir_submit + \"\\\\models\\\\t01\\\\\"\n",
    "dir_model_06s = dir_submit + \"\\\\models\\\\t06\\\\\"\n",
    "dir_model_12s = dir_submit + \"\\\\models\\\\t12\\\\\"\n",
    "dir_model_fusion = dir_submit + \"\\\\models\\\\ensemble\\\\\"\n",
    "dir_model_03s = dir_submit + \"\\\\models\\\\t03\\\\\"\n",
    "\n",
    "# set output folder\n",
    "dir_out_exp = dir_submit + \"\\\\result\\\\EXP\\\\\"\n",
    "if os.path.isdir(dir_out_exp) == False:\n",
    "    os.makedirs(dir_out_exp)\n",
    "\n",
    "dir_out_va = dir_submit + \"\\\\result\\\\VA\\\\\"\n",
    "if os.path.isdir(dir_out_va) == False:\n",
    "    os.makedirs(dir_out_va)\n",
    "\n",
    "# read models\n",
    "model_VA_A_01s = read_models(dir_model_01s, \"VA_A\", 1)\n",
    "model_VA_A_06s = read_models(dir_model_06s, \"VA_A\", 6)\n",
    "model_VA_A_12s = read_models(dir_model_12s, \"VA_A\", 12)\n",
    "model_VA_A_03s = read_models(dir_model_03s, \"VA_A\", 3)\n",
    "\n",
    "model_VA_V_01s = read_models(dir_model_01s, \"VA_V\", 1)\n",
    "model_VA_V_06s = read_models(dir_model_06s, \"VA_V\", 6)\n",
    "model_VA_V_12s = read_models(dir_model_12s, \"VA_V\", 12)\n",
    "model_VA_V_03s = read_models(dir_model_03s, \"VA_V\", 3)\n",
    "\n",
    "model_EXP_01s = read_models(dir_model_01s, \"EXP\", 1)\n",
    "model_EXP_06s = read_models(dir_model_06s, \"EXP\", 6)\n",
    "model_EXP_12s = read_models(dir_model_12s, \"EXP\", 12)\n",
    "model_EXP_03s = read_models(dir_model_03s, \"EXP\", 3)\n",
    "\n",
    "model_VA_A_single = load_model(dir_model_fusion + \"model_fusion_single_\" + \"VA_A\" + \".pickle\")\n",
    "model_VA_A_multi = load_model(dir_model_fusion + \"model_fusion_multi_\" + \"VA_A\" + \".pickle\")\n",
    "\n",
    "model_VA_V_single = load_model(dir_model_fusion + \"model_fusion_single_\" + \"VA_V\" + \".pickle\")\n",
    "model_VA_V_multi = load_model(dir_model_fusion + \"model_fusion_multi_\" + \"VA_V\" + \".pickle\")\n",
    "\n",
    "model_EXP_single = load_model(dir_model_fusion + \"model_fusion_single_\" + \"EXP\" + \".pickle\")\n",
    "model_EXP_multi = load_model(dir_model_fusion + \"model_fusion_multi_\" + \"EXP\" + \".pickle\")\n",
    "\n",
    "# search files of test: exp\n",
    "file_test_exp_01s = dir_test_exp + \"*_01s.h5\"\n",
    "files_test_exp_01s = [\n",
    "    filename for filename in sorted(glob.glob(file_test_exp_01s))\n",
    "]\n",
    "log = \"file number of val 01s: {0}\".format(len(files_test_exp_01s))\n",
    "print(log)\n",
    "\n",
    "file_test_exp_06s = dir_test_exp + \"*_06s.h5\"\n",
    "files_test_exp_06s = [\n",
    "    filename for filename in sorted(glob.glob(file_test_exp_06s))\n",
    "]\n",
    "log = \"file number of val 06s: {0}\".format(len(files_test_exp_06s))\n",
    "print(log)\n",
    "\n",
    "file_test_exp_12s = dir_test_exp + \"*_12s.h5\"\n",
    "files_test_exp_12s = [\n",
    "    filename for filename in sorted(glob.glob(file_test_exp_12s))\n",
    "]\n",
    "log = \"file number of val 12s: {0}\".format(len(files_test_exp_12s))\n",
    "print(log)\n",
    "\n",
    "file_test_exp_03s = dir_test_exp + \"*_03s.h5\"\n",
    "files_test_exp_03s = [\n",
    "    filename for filename in sorted(glob.glob(file_test_exp_03s))\n",
    "]\n",
    "log = \"file number of val 03s: {0}\".format(len(files_test_exp_03s))\n",
    "print(log)\n",
    "\n",
    "\n",
    "# search files of test: va\n",
    "file_test_va_01s = dir_test_va + \"*_01s.h5\"\n",
    "files_test_va_01s = [\n",
    "    filename for filename in sorted(glob.glob(file_test_va_01s))\n",
    "]\n",
    "log = \"file number of val 01s: {0}\".format(len(files_test_va_01s))\n",
    "print(log)\n",
    "\n",
    "file_test_va_06s = dir_test_va + \"*_06s.h5\"\n",
    "files_test_va_06s = [\n",
    "    filename for filename in sorted(glob.glob(file_test_va_06s))\n",
    "]\n",
    "log = \"file number of val 06s: {0}\".format(len(files_test_va_06s))\n",
    "print(log)\n",
    "\n",
    "file_test_va_12s = dir_test_va + \"*_12s.h5\"\n",
    "files_test_va_12s = [\n",
    "    filename for filename in sorted(glob.glob(file_test_va_12s))\n",
    "]\n",
    "log = \"file number of val 12s: {0}\".format(len(files_test_va_12s))\n",
    "print(log)\n",
    "\n",
    "file_test_va_03s = dir_test_va + \"*_03s.h5\"\n",
    "files_test_va_03s = [\n",
    "    filename for filename in sorted(glob.glob(file_test_va_03s))\n",
    "]\n",
    "log = \"file number of val 03s: {0}\".format(len(files_test_va_03s))\n",
    "print(log)\n",
    "\n",
    "\n",
    "# substruct features\n",
    "dir_feature = dir_base + \"\\\\features\\\\\"\n",
    "#dir_feature = None\n",
    "\n",
    "\n",
    "#VA\n",
    "max_count = len(files_test_va_01s)\n",
    "\n",
    "#valence,arousal .3g\n",
    "#max_count=5\n",
    "for i in range(max_count):\n",
    "    \n",
    "    f01 = files_test_va_01s[i]\n",
    "    f06 = files_test_va_06s[i]\n",
    "    f12 = files_test_va_12s[i]\n",
    "    f03 = files_test_va_03s[i]\n",
    "    # VA_A\n",
    "    pred_VA_A_multi = predict_multi_VA_A(f01, f06, f12, f03, dir_feature)\n",
    "    # VA_V\n",
    "    pred_VA_V_multi = predict_multi_VA_V(f01, f06, f12, f03, dir_feature)\n",
    "    \n",
    "    # meake file name without ext\n",
    "    name = os.path.splitext(os.path.basename(f01))[0].replace(\"_01s\",'')\n",
    "    file_out = dir_out_va + name + \".txt\"\n",
    "    \n",
    "    data = pd.DataFrame()\n",
    "    data[\"valence\"] = pred_VA_V_multi\n",
    "    data[\"arousal\"] = pred_VA_A_multi\n",
    "    #data = data.append(data.tail(1))\n",
    "    \n",
    "    data.to_csv(file_out, index=False, float_format='%.3g')\n",
    "    \n",
    "    log = \"{0}/{1}, shape: {2}\".format(i+1, max_count, data.shape)\n",
    "    print(log)\n",
    "\n",
    "log = \"*** finished ***\"\n",
    "print(log)\n",
    "\n",
    "\n",
    "#EXP\n",
    "max_count = len(files_test_exp_01s)\n",
    "\n",
    "#valence,arousal .3g\n",
    "#\"Neutral,Anger,Disgust,Fear,Happiness,Sadness,Surprise\"\n",
    "for i in range(max_count):\n",
    "    \n",
    "    f01 = files_test_exp_01s[i]\n",
    "    f06 = files_test_exp_06s[i]\n",
    "    f12 = files_test_exp_12s[i]\n",
    "    f03 = files_test_exp_03s[i]\n",
    "    # EXP\n",
    "    pred_EXP_multi = predict_multi_EXP(f01, f06, f12, f03, dir_feature)\n",
    "    \n",
    "    # meake file name without ext\n",
    "    name = os.path.splitext(os.path.basename(f01))[0].replace(\"_01s\",'')\n",
    "    file_out = dir_out_exp + name + \".txt\"\n",
    "    \n",
    "    np.savetxt(file_out, pred_EXP_multi, delimiter='\\n', fmt ='%d', \n",
    "               header='Neutral,Anger,Disgust,Fear,Happiness,Sadness,Surprise', comments='')\n",
    "    \n",
    "    log = \"{0}/{1}, shape: {2}\".format(i+1, max_count, pred_EXP_multi.shape)\n",
    "    print(log)\n",
    "\n",
    "log = \"*** finished ***\"\n",
    "print(log)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
